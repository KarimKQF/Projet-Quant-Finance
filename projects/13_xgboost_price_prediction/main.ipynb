{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# XGBoost Price Prediction (Advanced)\n",
                "\n",
                "This notebook implements an advanced XGBoost pipeline for price direction prediction.\n",
                "Key enhancements:\n",
                "- **Advanced Features**: MACD, Bollinger Bands, ATR.\n",
                "- **Hyperparameter Tuning**: Using GridSearchCV to find optimal model parameters.\n",
                "- **Feature Importance**: Visualizing which technical indicators matter most."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import xgboost as xgb\n",
                "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
                "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix\n",
                "\n",
                "from data_generator import generate_gbm_data\n",
                "from feature_engineering import add_technical_indicators\n",
                "\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Prep & Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "raw_df = generate_gbm_data(n_samples=2000)\n",
                "df = add_technical_indicators(raw_df)\n",
                "print(f\"Data Shape: {df.shape}\")\n",
                "df.tail()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features = ['SMA_10', 'SMA_50', 'RSI', 'MACD', 'MACD_Signal', 'BB_Upper', 'BB_Lower', 'ATR', 'Log_Return', 'Volume']\n",
                "target = 'Target'\n",
                "\n",
                "X = df[features]\n",
                "y = df[target]\n",
                "\n",
                "# Time-series split (No random shuffle)\n",
                "split_point = int(len(df) * 0.8)\n",
                "X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
                "y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Hyperparameter Tuning (Grid Search)\n",
                "We use TimeSeriesSplit for cross-validation to respect temporal order."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tscv = TimeSeriesSplit(n_splits=3)\n",
                "\n",
                "param_grid = {\n",
                "    'n_estimators': [50, 100, 200],\n",
                "    'max_depth': [3, 5, 7],\n",
                "    'learning_rate': [0.01, 0.1, 0.2],\n",
                "    'reg_alpha': [0, 0.1, 0.5] # L1 regularization\n",
                "}\n",
                "\n",
                "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
                "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, cv=tscv, scoring='accuracy', verbose=1, n_jobs=-1)\n",
                "\n",
                "print(\"Starting Grid Search...\")\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
                "best_model = grid_search.best_estimator_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = best_model.predict(X_test)\n",
                "accuracy = accuracy_score(y_test, predictions)\n",
                "\n",
                "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n",
                "print(classification_report(y_test, predictions))\n",
                "\n",
                "plot_confusion_matrix(best_model, X_test, y_test, cmap='Blues')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "xgb.plot_importance(best_model, ax=ax, importance_type='gain')\n",
                "plt.title('Feature Importance (Gain)')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}